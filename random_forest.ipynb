{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('./spotify_songs.csv') \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
      "       'track_album_id', 'track_album_name', 'track_album_release_date',\n",
      "       'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre',\n",
      "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'duration_ms'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       track_popularity  danceability        energy           key  \\\n",
      "count      32828.000000  32828.000000  32828.000000  32828.000000   \n",
      "mean          42.483551      0.654850      0.698603      5.373949   \n",
      "std           24.980476      0.145092      0.180916      3.611572   \n",
      "min            0.000000      0.000000      0.000175      0.000000   \n",
      "25%           24.000000      0.563000      0.581000      2.000000   \n",
      "50%           45.000000      0.672000      0.721000      6.000000   \n",
      "75%           62.000000      0.761000      0.840000      9.000000   \n",
      "max          100.000000      0.983000      1.000000     11.000000   \n",
      "\n",
      "           loudness          mode   speechiness  acousticness  \\\n",
      "count  32828.000000  32828.000000  32828.000000  32828.000000   \n",
      "mean      -6.719529      0.565737      0.107053      0.175352   \n",
      "std        2.988641      0.495667      0.101307      0.219644   \n",
      "min      -46.448000      0.000000      0.000000      0.000000   \n",
      "25%       -8.171250      0.000000      0.041000      0.015100   \n",
      "50%       -6.166000      1.000000      0.062500      0.080400   \n",
      "75%       -4.645000      1.000000      0.132000      0.255000   \n",
      "max        1.275000      1.000000      0.918000      0.994000   \n",
      "\n",
      "       instrumentalness      liveness       valence         tempo  \\\n",
      "count      32828.000000  32828.000000  32828.000000  32828.000000   \n",
      "mean           0.084760      0.190175      0.510556    120.883642   \n",
      "std            0.224245      0.154313      0.233152     26.903632   \n",
      "min            0.000000      0.000000      0.000000      0.000000   \n",
      "25%            0.000000      0.092700      0.331000     99.961000   \n",
      "50%            0.000016      0.127000      0.512000    121.984000   \n",
      "75%            0.004830      0.248000      0.693000    133.918250   \n",
      "max            0.994000      0.996000      0.991000    239.440000   \n",
      "\n",
      "         duration_ms  \n",
      "count   32828.000000  \n",
      "mean   225796.829779  \n",
      "std     59836.492346  \n",
      "min      4000.000000  \n",
      "25%    187804.500000  \n",
      "50%    216000.000000  \n",
      "75%    253581.250000  \n",
      "max    517810.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a random forest classifier to demonstrate genre classification. The we propose a new entropy based clustering scheme: Root-Clustering which modifies the random forest classifier to cluster data in an unsupervised manner. This results in a fork of hierachical clustering whereby it is top down and the splitting decision is based on entropy instead of desicion based. This provides a few benefits:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is more interpretable (each cluster can be traced)\n",
    "- It works on mixed data types (categorical and numerical) without special transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pitfall of this approach is that it does not compute the covariance matrix therefore assumes independence of features and works for such datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end we compare our proposed algortihm to traditional algorithms (KMeans, AgglomerativeClustering [Hierachical Clustering], DBSCAN) using the sillhouette score and interpretability metrics such as number of clusters, feature usage, and average rule length. We also provide some visualisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we fit a hold-out set to Root-Clustering to generate novel playlists and do song recommendation by deducing which songs from the online spotify archive fits it to each playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'tempo']].values\n",
    "y = df['playlist_genre'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomForest: \n",
    "    def __init__(self, trees, n_trees, max_feature, prediction_aggregation_calculation):\n",
    "        self.n_estimators = n_trees # Number of trees\n",
    "        self.max_features = max_feature # Number of features to consider when looking for the best split\n",
    "        self.tree_feature_indexes = [] # To store the feature indexes used for each tree\n",
    "        self.prediction_aggregation_calculation = prediction_aggregation_calculation # Function to aggregate predictions from all trees\n",
    "        self.trees = trees\n",
    "\n",
    "    # Bootstrapping the data without mixing types\n",
    "    def _make_random_subset(self, X, y, n_subsets, replacement=True):\n",
    "        subsets = []\n",
    "        sample_size = X.shape[0]\n",
    "        \n",
    "        for i in range(n_subsets):\n",
    "            # Sample indices and then select rows from X and y separately\n",
    "            indices = np.random.choice(sample_size, size=sample_size, replace=replacement)\n",
    "            subsets.append({\"X\": X[indices], \"y\": y[indices]})\n",
    "        \n",
    "        return subsets\n",
    "\n",
    "    def train(self, X, y): \n",
    "        n_features = X.shape[1]\n",
    "        if self.max_features is None:\n",
    "            self.max_features = int(math.sqrt(n_features)) #\n",
    "\n",
    "        subsets = self._make_random_subset(X, y, self.n_estimators) # Create n_estimators subsets of data\n",
    "\n",
    "        for i, subset in enumerate(subsets):\n",
    "            X_subset, y_subset = subset[\"X\"], subset[\"y\"]\n",
    "            \n",
    "            # Bagging: randomly select a subset of features for each tree\n",
    "            idx = np.random.choice(range(n_features), size=self.max_features, replace=True)\n",
    "            self.tree_feature_indexes.append(idx)\n",
    "            X_subset = X_subset[:, idx]\n",
    "            # Fit the tree on the subset; y_subset is already 1D\n",
    "            self.trees[i].fit(X_subset, y_subset)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        # Prepare an empty array for predictions (dtype=object for string labels)\n",
    "        y_preds = np.empty((test_X.shape[0], self.n_estimators), dtype=object)\n",
    "        # Get predictions from each tree\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            features_index = self.tree_feature_indexes[i]\n",
    "            X_selected_features = test_X[:, features_index]\n",
    "            y_preds[:, i] = tree.predict(X_selected_features)\n",
    "        # Aggregate predictions using the provided aggregation method\n",
    "        y_pred = self.prediction_aggregation_calculation(y_preds)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class RandomForestClassifier(RandomForest): \n",
    "    def __init__(self, max_feature, max_depth, n_trees=100, min_samples_split=2):\n",
    "        self.prediction_aggregation_calculation = self._maximum_vote_calculation\n",
    "        self.trees = []\n",
    "        for _ in range(n_trees): # Create n_trees Decision Trees\n",
    "            self.trees.append(DecisionTreeClassifier(min_samples_split=min_samples_split, max_depth=max_depth))\n",
    "        \n",
    "        super().__init__(\n",
    "            trees=self.trees,\n",
    "            n_trees=n_trees,\n",
    "            max_feature=max_feature,\n",
    "            prediction_aggregation_calculation=self.prediction_aggregation_calculation\n",
    "        ) \n",
    "    \n",
    "    def _maximum_vote_calculation(self, y_preds): # Aggregate predictions using majority voting\n",
    "        y_pred = np.empty(y_preds.shape[0], dtype=object)\n",
    "        for i, sample_predictions in enumerate(y_preds):\n",
    "            counter = Counter(sample_predictions)\n",
    "            y_pred[i] = counter.most_common(1)[0][0]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26262, 8) (26262,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.5283615843596279\n",
      "Best Parameters: Trees: 500, Max Features: 4, Min Samples Split: 8, Max Depth: 16\n",
      "Accuracy: 0.5290892476393543\n",
      "Precision: 0.5182378085430867\n",
      "Recall: 0.5290892476393543\n",
      "F1 Score: 0.5216076966395825\n",
      "Library Random Forest Accuracy: 0.5523911056960098\n",
      "Library Random Forest Precision: 0.5456045098311852\n",
      "Library Random Forest Recall: 0.5523911056960098\n",
      "Library Random Forest F1 Score: 0.5475747657663256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier as SklearnRandomForest\n",
    "\n",
    "\n",
    "n_trees_options = [150,300,500,1000]\n",
    "max_feature_options = [2,3,4]\n",
    "min_samples_split_options = [2,4,6,8]\n",
    "max_depth_options = [8,10,12,14,16]\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Iterate through all combinations of hyperparameters and train the Random Forest Classifier\n",
    "for n_trees, max_feature, min_samples_split, max_depth in product(\n",
    "    n_trees_options, max_feature_options, min_samples_split_options, max_depth_options\n",
    "):\n",
    "    random_forest_classifier = RandomForestClassifier(\n",
    "        n_trees=n_trees,\n",
    "        max_feature=max_feature,\n",
    "        min_samples_split=min_samples_split,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    random_forest_classifier.train(X_train, y_train)\n",
    "    y_pred = random_forest_classifier.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = (n_trees, max_feature, min_samples_split, max_depth)\n",
    "\n",
    "print(f\"Best F1 Score: {best_f1}\")\n",
    "print(f\"Best Parameters: Trees: {best_params[0]}, Max Features: {best_params[1]}, Min Samples Split: {best_params[2]}, Max Depth: {best_params[3]}\")\n",
    "y_pred = random_forest_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "model_random_forest = SklearnRandomForest(n_estimators=best_params[0], max_depth=best_params[-1], min_samples_split=best_params[-2], max_features=best_params[1], random_state=42)\n",
    "model_random_forest.fit(X_train, y_train)\n",
    "y_pred = model_random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Library Random Forest Accuracy: {accuracy}\")\n",
    "print(f\"Library Random Forest Precision: {precision}\")\n",
    "print(f\"Library Random Forest Recall: {recall}\")\n",
    "print(f\"Library Random Forest F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
